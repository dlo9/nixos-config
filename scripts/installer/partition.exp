#!/usr/bin/env -S expect -f

# This partitions a disk for encrypted ZFS-on-root EFI and legacy boot
#
# This script:
#   - Unmounts and erases the given disks
#   - Partitions the given disks with:
#     - Legacy boot partition
#     - UEFI boot partition
#     - Swap partition
#     - ZFS partition
#   - Creates a ZFS pool, either in mirror or disk mode depeneding on the number of disks used

###################
##### Prelude #####
###################

# Include library functions and set a log file
source lib.exp
log_file partition.log

######################
##### Parameters #####
######################

source inputs.exp
requireVars disks vdevType adminUser zpoolPassword efiSize swapSize installDir

#####################
##### Functions #####
#####################

# Notify the kernel of partition changes so that commands can see the new partitions
proc refreshDisk {disk} {
  sleep 1
  exec partprobe $disk
  sleep 1
}

# Erase existing filesystem/partition info for a disk
proc eraseDisk {disk} {
  _info "Erasing disk $disk..."

  # Erase partitions
  set partitions [glob -nocomplain "${disk}-part\[1-9\]"]
  if {[llength $partitions] > 0} {
    exec wipefs -a {*}$partitions
  }

  # Erase partition table
  exec wipefs -a $disk

  _success "Erased disk $disk"

  refreshDisk $disk
}

# Reset the system state by unmounting, unswapping, exporting, and erasing disks
# This is mainly useful for resetting the system back to its starting state in case this script needs to be re-run, otherwise errors abound
proc resetDisks {disks} {
  source export-disks.exp

  foreach disk $disks {
    eraseDisk $disk
  }
}

proc partitionDisk {disk efiSize swapSize} {
  _info "Partitioning disk $disk"
  exec sgdisk --zap-all "$disk"
  refreshDisk "$disk"

  _info "Creating partition #1: BIOS"
  exec sgdisk -a1 --new 1:24K:+1000K --typecode 1:EF02 --change-name 1:BIOS "$disk"
  refreshDisk "$disk"

  _info "Creating partition #2: EFI"
  exec sgdisk --new 2:1M:+$efiSize --typecode 2:EF00 --change-name 2:EFI "$disk"
  refreshDisk "$disk"

  exec mkfs.vfat -n EFI "${disk}-part2"

  _info "Creating partition #3: swap"
  exec sgdisk --new 3:0:+$swapSize --typecode 3:8200 --change-name 3:swap "$disk"
  refreshDisk "$disk"

  exec -ignorestderr mkswap -L swap "${disk}-part3"
  exec swapon "${disk}-part3"

  # This uses the remaining space
  _info "Creating partition #4: ZFS pool"
  exec sgdisk --new 4:0:0 --typecode 4:8300 --change-name 4:pool "$disk"
  refreshDisk "$disk"
}

proc partitionDisks {disks efiSize swapSize} {
  foreach disk $disks {
    partitionDisk $disk $efiSize $swapSize
  }
}

proc createZpool {disks vdevType zpoolPassword installDir} {
  _info "Creating main pool"

  set partitions [lmap disk $disks {expr {"$disk-part4"}}]

  # Build the zpool command
  set zpoolCmd [subst -nocommands {
    zpool
    create
    -O compression=zstd
    -O encryption=aes-256-gcm
    -O keylocation=prompt
    -O keyformat=passphrase
    -O dnodesize=auto
    -o ashift=12
    -o autotrim=on
    -O acltype=posixacl
    -O canmount=off
    -O normalization=formD
    -O atime=off
    -O xattr=sa
    -R $installDir
    pool
  }]

  if { $vdevType != "disk" } {
    lappend zpoolCmd $vdevType
  }

  lappend zpoolCmd {*}$partitions

  # Spawn the command
  spawn {*}$zpoolCmd

  expect "Enter new passphrase:"
  sleep .5
  send "$zpoolPassword\n"

  expect "Re-enter new passphrase:"
  sleep .5
  send "$zpoolPassword\n"

  expect eof
}

proc createDatasets {adminUser} {
  # System
  _info "Creating system datasets..."

  # Reserved space so that deletes can occur even if the pool fills
  exec zfs create  -o canmount=off -o mountpoint=none -o refreservation=1G pool/reserved

  # System root
  exec zfs create  -o canmount=off -o mountpoint=none pool/nixos
  exec zfs create  -o canmount=noauto -o mountpoint=/ pool/nixos/root
  # Mount it now, or the mount later will overlay the other dataset mounts and `zpool export` can fail
  exec zfs mount pool/nixos/root

  # Containerization
  exec zfs create -o canmount=off -o mountpoint=none pool/kubernetes
  exec zfs create pool/kubernetes/storage
  exec zfs create pool/kubernetes/containerd
  exec zfs create -V 100G pool/kubernetes/containerd/overlayfs-snapshotter
  exec mkfs.ext4 /dev/zvol/pool/kubernetes/containerd/overlayfs-snapshotter
  exec mount /dev/zvol/pool/kubernetes/containerd/overlayfs-snapshotter /var/lib/containerd/io.containerd.snapshotter.v1.overlayfs

  # Don't recommend using this
  exec zfs create  -o mountpoint=/var/lib/containerd/io.containerd.snapshotter.v1.zfs pool/kubernetes/containerd/zfs-snapshotter

  # User datasets
  _info "Creating user datasets..."
  exec zfs create  -o canmount=off -o mountpoint=/home pool/home
  exec zfs create  -o mountpoint=/root pool/home/root
  exec zfs create  "pool/home/$adminUser"
}

# Create an initial snapshot
proc snapshot {} {
  _info "Creating initial snapshot"
  exec zfs snapshot -r pool@empty
}

# Mounts the zpool and EFI directories
proc mountDisks {disks installDir} {
  _info "Mounting target disks..."

  for {set i 0} {$i < [llength $disks]} {incr i} {
    set disk [lindex $disks $i]
    exec mount -o X-mount.mkdir "${disk}-part2" "$installDir/boot/efi$i"
  }
}

#################
##### Start #####
#################


_info "##### Starting Partitioning #####"

requireUser "root"

resetDisks $disks
partitionDisks $disks $efiSize $swapSize
createZpool $disks $vdevType $zpoolPassword $installDir
createDatasets $adminUser
snapshot
mountDisks $disks $installDir

_success "##### Finished Partitioning #####"
